{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = 'flowers'\n",
    "print(data_dir)\n",
    "\n",
    "# Define directories for training, validation, and testing\n",
    "train_dir = f\"{data_dir}/train\"\n",
    "valid_dir = f\"{data_dir}/valid\"\n",
    "test_dir = f\"{data_dir}/test\"\n",
    "print(train_dir, valid_dir, test_dir)\n",
    "\n",
    "# Define transformations for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets using ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=test_transforms)\n",
    "\n",
    "# Print dataset information\n",
    "print(train_data, test_data, valid_data)\n",
    "\n",
    "# Define dataloaders for the datasets\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
    "\n",
    "# Load category label mapping from JSON file\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    print(cat_to_name)\n",
    "\n",
    "no_output_categories = len(cat_to_name)\n",
    "\n",
    "# Build the network\n",
    "hidden_units = 4096\n",
    "model = models.vgg16_bn(weights='DEFAULT')\n",
    "\n",
    "# Freeze the parameters of the pretrained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define the classifier\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, hidden_units)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout1', nn.Dropout(0.05)),\n",
    "    ('fc2', nn.Linear(hidden_units, no_output_categories)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "# Replace the pretrained classifier with the new one\n",
    "model.classifier = classifier\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f'The device in use is {device}.\\n')\n",
    "\n",
    "# Set training hyperparameters\n",
    "epochs = 10\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()\n",
    "print_every = 20\n",
    "\n",
    "# Initialize metrics\n",
    "running_loss = 0\n",
    "running_accuracy = 0\n",
    "validation_losses, training_losses = [], []\n",
    "\n",
    "# Training process\n",
    "for e in range(epochs):\n",
    "    batches = 0\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        start = time.time()\n",
    "        batches += 1\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate metrics\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_ps, top_class = ps.topk(1, dim=1)\n",
    "        matches = (top_class == labels.view(*top_class.shape)).type(torch.FloatTensor)\n",
    "        accuracy = matches.mean()\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += accuracy.item()\n",
    "\n",
    "        # Validation every print_every batches\n",
    "        if batches % print_every == 0:\n",
    "            end = time.time()\n",
    "            training_time = end - start\n",
    "            start = time.time()\n",
    "\n",
    "            # Validation metrics\n",
    "            validation_loss = 0\n",
    "            validation_accuracy = 0\n",
    "\n",
    "            model.eval() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
