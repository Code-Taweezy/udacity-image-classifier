{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data_dir = 'flowers'\n",
    "train_dir = f\"{data_dir}/train\"\n",
    "valid_dir = f\"{data_dir}/valid\"\n",
    "test_dir = f\"{data_dir}/test\"\n",
    "\n",
    "# Define transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets using ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "# Define dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Load category mapping\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "no_output_categories = len(cat_to_name)\n",
    "\n",
    "# Build and train the classifier\n",
    "hidden_units = 512  # Changed hidden units for a different architecture\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define the classifier\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, hidden_units)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('dropout', nn.Dropout(0.2)),  # Increased dropout for regularization\n",
    "    ('fc2', nn.Linear(hidden_units, no_output_categories)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training hyperparameters\n",
    "epochs = 5  # Reduced epochs for quicker training\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01, momentum=0.9)  # Changed optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Training process\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_ps, top_class = ps.topk(1, dim=1)\n",
    "        matches = (top_class == labels.view(*top_class.shape)).type(torch.FloatTensor)\n",
    "        running_accuracy += matches.mean().item()\n",
    "\n",
    "    print(f\"Epoch {e+1}/{epochs} - Loss: {running_loss/len(trainloader):.3f}, Accuracy: {running_accuracy/len(trainloader)*100:.2f}%\")\n",
    "\n",
    "# Testing the network\n",
    "test_accuracy = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        log_ps = model(images)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_ps, top_class = ps.topk(1, dim=1)\n",
    "        matches = (top_class == labels.view(*top_class.shape)).type(torch.FloatTensor)\n",
    "        test_accuracy += matches.mean().item()\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy/len(testloader)*100:.2f}%')\n",
    "\n",
    "\n",
    "# Save the checkpoint\n",
    "model.class_to_idx = train_data.class_to_idx  # Attach class to index mapping to the model\n",
    "\n",
    "# Save the checkpoint in the current directory\n",
    "destination_directory = None\n",
    "class_to_idx = train_data.class_to_idx  # Improves label to name mapping\n",
    "\n",
    "# Save the model's state_dict\n",
    "def save_model(trained_model, hidden_units, output_units, destination_directory, model_arch, class_to_idx):\n",
    "    model_checkpoint = {\n",
    "        'model_arch': model_arch,\n",
    "        'clf_input': 25088,\n",
    "        'clf_output': output_units,\n",
    "        'clf_hidden': hidden_units,\n",
    "        'state_dict': trained_model.state_dict(),\n",
    "        'model_class_to_index': class_to_idx,\n",
    "        'epochs': epochs,  # Save the number of epochs\n",
    "        'optimizer_state': optimizer.state_dict()  # Save optimizer state\n",
    "    }\n",
    "    \n",
    "    # Save model in current directory\n",
    "    save_path = f\"{destination_directory}/{model_arch}_checkpoint.pth\" if destination_directory else f\"{model_arch}_checkpoint.pth\"\n",
    "    torch.save(model_checkpoint, save_path)\n",
    "    print(f\"{model_arch} successfully saved to {save_path}\")\n",
    "\n",
    "# Call save_model\n",
    "save_model(model, hidden_units, no_output_categories, destination_directory, 'vgg16_bn', class_to_idx)\n",
    "\n",
    "# Loading the checkpoint\n",
    "checkpoint = 'vgg16_bn_checkpoint.pth'\n",
    "\n",
    "# Function that accepts two arguments: filepath (location of checkpoint) and device (gpu/cpu)\n",
    "def load_checkpoint(filepath, device):\n",
    "    map_location = 'cuda' if device == \"gpu\" else 'cpu'\n",
    "    checkpoint = torch.load(filepath, map_location=map_location)\n",
    "\n",
    "    return (checkpoint['model_arch'], checkpoint['clf_input'], checkpoint['clf_output'],\n",
    "            checkpoint['clf_hidden'], checkpoint['state_dict'], checkpoint['model_class_to_index'])\n",
    "\n",
    "# Load the checkpoint\n",
    "model_arch, input_units, output_units, hidden_units, state_dict, class_to_idx = load_checkpoint(checkpoint, device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Inference for classification\n",
    "practice_img = './flowers/test/19/image_06186.jpg'\n",
    "\n",
    "# Processes a PIL image for use in a PyTorch model\n",
    "def process_image(image):\n",
    "    with Image.open(image) as img:\n",
    "        img = img.convert('RGB')\n",
    "        img.thumbnail((256, 256))  # Resize while maintaining aspect ratio\n",
    "        width, height = img.size\n",
    "\n",
    "        # Center crop\n",
    "        left = (width - 224) / 2\n",
    "        top = (height - 224) / 2\n",
    "        right = (width + 224) / 2\n",
    "        bottom = (height + 224) / 2\n",
    "        img = img.crop((left, top, right, bottom))\n",
    "\n",
    "        # Convert to tensor and normalize\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        img_tensor = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(img_tensor)\n",
    "        \n",
    "        return img_tensor.numpy()\n",
    "\n",
    "# Display the original and preprocessed image\n",
    "def imshow(image, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    image = image.transpose((1, 2, 0))  # Change from CHW to HWC\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    return ax\n",
    "\n",
    "# Display original image\n",
    "original_image = Image.open(practice_img)\n",
    "imshow(process_image(practice_img))\n",
    "\n",
    "# Class Prediction\n",
    "def class_to_label(file, classes):\n",
    "    with open(file, 'r') as f:\n",
    "        class_mapping = json.load(f)\n",
    "    return [class_mapping[c] for c in classes]\n",
    "\n",
    "# Invert the class_to_idx mapping\n",
    "idx_mapping = {v: k for k, v in class_to_idx.items()}\n",
    "\n",
    "# Predict the class of an image using the deep learning model\n",
    "def predict(image_path, model, idx_mapping, topk, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pre_processed_image = torch.from_numpy(process_image(image_path)).unsqueeze(0).to(device)\n",
    "        log_ps = model(pre_processed_image)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_ps, top_idx = ps.topk(topk, dim=1)\n",
    "        \n",
    "        probabilities = top_ps.squeeze().tolist()\n",
    "        classes = [idx_mapping[idx.item()] for idx in top_idx.squeeze()]\n",
    "        \n",
    "        return probabilities, classes\n",
    "\n",
    "# Print predictions\n",
    "def print_predictions(probabilities, classes, image_name, category_names=None):\n",
    "    print(f\"Predictions for image: {image_name}\")\n",
    "    \n",
    "    if category_names:\n",
    "        labels = class_to_label(category_names, classes)\n",
    "        for i, (prob, label, cls) in enumerate(zip(probabilities, labels, classes), 1):\n",
    "            print(f'{i}) {prob * 100:.2f}% {label.title()} | Class No. {cls}')\n",
    "    else:\n",
    "        for i, (prob, cls) in enumerate(zip(probabilities, classes), 1):\n",
    "            print(f'{i}) {prob * 100:.2f}% Class No. {cls}')\n",
    "    print('')\n",
    "\n",
    "# Get predictions for the practice image\n",
    "probabilities, classes = predict(practice_img, model, idx_mapping, 5, device)\n",
    "\n",
    "# Print out the predictions\n",
    "print_predictions(probabilities, classes, practice_img.split('/')[-1], 'cat_to_name.json')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
